{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1ce435d-42a4-4918-b263-d6c55bc99847",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:24: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:24: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/var/folders/zp/5k1kvm9j0t19cvq8h628kr8h0000gn/T/ipykernel_89768/2272103219.py:24: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  z = findall('_(\\d+).ome.tif',filename)[0]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "from os import path\n",
    "import numpy as np\n",
    "from skimage import io,util,filters\n",
    "from skimage.transform import EuclideanTransform, warp\n",
    "from scipy import ndimage\n",
    "\n",
    "from pystackreg import StackReg\n",
    "# from twophotonUtils import parse_unregistered_channels\n",
    "# from twophotonUtils import find_most_likely_z_slice_using_CC, z_translate_and_pad\n",
    "# from imageLoadingWidgets import LoadTimepointForInspection\n",
    "\n",
    "from os import path\n",
    "from glob import glob\n",
    "from re import findall\n",
    "from tqdm import tqdm\n",
    "\n",
    "import stackview\n",
    "\n",
    "# Extract the first ome.tiff file from every subfolder, load, then separate the two channels\n",
    "def sort_by_slice(filename):\n",
    "    z = findall('_(\\d+).ome.tif',filename)[0]\n",
    "    return int(z)\n",
    "\n",
    "def read_prairie_ome_xml(header_ome,channel_names,registerZ=False,reference_channel:int=None):\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    d = path.split(path.dirname(header_ome))[0]\n",
    "    if np.all([path.exists(path.join(d,f'{chan}_reg.tif')) for chan in channel_names]):\n",
    "        print(f'All *_reg channels exist for {channel_names} channels')\n",
    "        return\n",
    "    \n",
    "    # Load ome-tif\n",
    "    print(f'Loading {d}')\n",
    "    stack = io.imread(header_ome,is_ome=True)\n",
    "    \n",
    "    if stack.ndim > 3:\n",
    "        images = [im for im in stack]\n",
    "    else:\n",
    "        images = [stack]\n",
    "    \n",
    "    if registerZ and reference_channel is not None:\n",
    "        # Use StackReg\n",
    "        print(f'Registering {d}')\n",
    "        sr = StackReg(StackReg.TRANSLATION) # There should only be slight sliding motion within a single stack\n",
    "        T = sr.register_stack(images[reference_channel],\n",
    "                              reference='previous',n_frames=20,axis=0) #Obtain the transformation matrices\n",
    "        for i,im in enumerate(images):\n",
    "            images[i] = sr.transform_stack(im,tmats=T) # Apply to all channels\n",
    "\n",
    "    for i,im in enumerate(images):\n",
    "        output_path = path.join( d,f'{channel_names[i]}_reg.tif')\n",
    "        io.imsave(output_path,util.img_as_uint(im/im.max()),check_contrast=False)\n",
    "    \n",
    "    print(f'Saved with {output_path}')\n",
    "\n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9568d18f-f3bc-4bf8-8d96-0877492c4e4e",
   "metadata": {},
   "source": [
    "# 0. Get file paths\n",
    "\n",
    "Step one: Load all the OME-TIFFs and re-save as multipage TIFFs for each time point in region\n",
    "Will perform a StackReg on each stack just in case there is small movement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19abab39-819d-4905-9f35-b0a62ff99c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping /Users/xies/Library/CloudStorage/OneDrive-Stanford/Skin/Two photon/NMS/Dermal topography/01-26-2026 mTmG/F1 DOB 12-5-2025/Left paw R1/0. Day 0/ZSeries-01272026-1411-2353/\n",
      "Skipping /Users/xies/Library/CloudStorage/OneDrive-Stanford/Skin/Two photon/NMS/Dermal topography/01-26-2026 mTmG/M1 12-5-2025/Left paw R3/0. Day 0/ZSeries-01262026-1616-2349/\n",
      "Found 14 raw B/G stacks and 0 raw R/R_shg stacks\n"
     ]
    }
   ],
   "source": [
    "# dirname = '/Users/xies/Library/CloudStorage/OneDrive-Stanford/Skin/Two photon/NMS/Palbo senescence pilot/09-29-2025 Ear palbo pilot/M1tail 3017 H2B FUCCI/Right ear/4. Day 4/R2'\n",
    "dirname = '/Users/xies/Library/CloudStorage/OneDrive-Stanford/Tumor/Tumor pilots/09-29-2025 Mouse ear injection/Mouse 5352/Left ear'\n",
    "dirname = '/Users/xies/Library/CloudStorage/OneDrive-Stanford/Skin/Two photon/NMS/Dermal topography/01-26-2026 mTmG'\n",
    "\n",
    "subfolders = glob(path.join(dirname,'*/*/*/ZSeries*/'))\n",
    "\n",
    "header_ome_h2b = []\n",
    "header_ome_fucci = []\n",
    "\n",
    "for d in subfolders:\n",
    "    \n",
    "    ome_tifs = glob(path.join(d,'*.ome.tif'))\n",
    "    ome_tifs = sorted(ome_tifs) # Sort by channel #\n",
    "    ome_tifs = sorted(ome_tifs, key = sort_by_slice) # Sort by slice #\n",
    "    if len(ome_tifs) < 30:\n",
    "        print(f'Skipping {d}')\n",
    "    else:\n",
    "        if len(findall('1020nm',path.split(path.split(d)[0])[1])) == 0:\n",
    "            header_ome_h2b.append(ome_tifs[0])\n",
    "        else:\n",
    "            header_ome_fucci.append(ome_tifs[0])\n",
    "\n",
    "print(f'Found {len(header_ome_h2b)} raw B/G stacks and {len(header_ome_fucci)} raw R/R_shg stacks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "239439ad-4c34-4b80-a52f-71e3807c69c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final number of B/G channels: 0\n",
      "Final number of R/R_shg channels: 0\n"
     ]
    }
   ],
   "source": [
    "# Parse multiple ZSeries within the same subfolder\n",
    "from collections import defaultdict\n",
    "\n",
    "region_timepoints = defaultdict(list)\n",
    "for f in header_ome_h2b:\n",
    "    region_timepoints[ path.dirname(path.dirname(f)) ].append(f)\n",
    "# Go through each timepoint and pick the 'latest' (aka last-sorted) stack\n",
    "final_h2b_timepoints = []\n",
    "for list_of_f in region_timepoints.values():\n",
    "    list_of_f = sorted(list_of_f) # Rely on default sortings\n",
    "    final_h2b_timepoints.append(list_of_f[-1])\n",
    "\n",
    "region_timepoints = defaultdict(list)\n",
    "for f in header_ome_fucci:\n",
    "    region_timepoints[ path.dirname(path.dirname(f)) ].append(f)\n",
    "# Go through each timepoint and pick the 'latest' (aka last-sorted) stack\n",
    "final_fucci_timepoints = []\n",
    "for list_of_f in region_timepoints.values():\n",
    "    list_of_f = sorted(list_of_f) # Rely on default sortings\n",
    "    final_fucci_timepoints.append(list_of_f[-1])\n",
    "\n",
    "print(f'Final number of B/G channels: {len(final_h2b_timepoints)}')\n",
    "print(f'Final number of R/R_shg channels: {len(final_fucci_timepoints)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375b7a4c-bf0a-463e-8130-7bae031cfc5e",
   "metadata": {},
   "source": [
    "# 1. Load each OME-XML and resave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "93b9f69b-7ed7-413d-a336-707af34ba48e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "registerZ = False # Perform an 'internal' stackreg?\n",
    "\n",
    "# Load B/G (H2B)\n",
    "for header_h2b in final_h2b_timepoints:\n",
    "    _ = read_prairie_ome_xml(header_h2b,channel_names = ['R','G','B'],\n",
    "                             reference_channel=0, registerZ=registerZ)\n",
    "\n",
    "# # Load R/R_Shg (FUCCI)\n",
    "# for header_fucci in final_fucci_timepoints:\n",
    "#     _ = read_prairie_ome_xml(header_fucci,channel_names = ['R','R_shg'], reference_idx=0, registerZ=registerZ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dd218f-a290-4a7f-8d2d-addc1958fca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ec153a-0601-4625-b0a0-4cb0effe5585",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
